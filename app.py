import streamlit as st
from PIL import Image
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.models import Model

# --- C√ÅC H√ÄM T·∫¢I M√î H√åNH V√Ä TOKENIZER (S·ª≠ d·ª•ng cache ƒë·ªÉ t·ªëi ∆∞u) ---

@st.cache_resource
def load_models_and_tokenizer():
    """T·∫£i m√¥ h√¨nh t·∫°o ch√∫ th√≠ch, m√¥ h√¨nh ResNet50 ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† tokenizer."""
    
    # T·∫£i m√¥ h√¨nh ch√≠nh
    try:
        caption_model = load_model('best_model_with_attention.h5')
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i file 'best_model_with_attention.h5': {e}")
        st.error("Vui l√≤ng ƒë·∫£m b·∫£o file m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªÅ v√† ƒë·∫∑t ƒë√∫ng trong th∆∞ m·ª•c.")
        return None, None, None

    # T·∫£i tokenizer
    try:
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i file 'tokenizer.pkl': {e}")
        st.error("Vui l√≤ng ƒë·∫£m b·∫£o file tokenizer ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªÅ v√† ƒë·∫∑t ƒë√∫ng trong th∆∞ m·ª•c.")
        return None, None, None
        
    # T·∫£i m√¥ h√¨nh ResNet50 ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
    resnet_model = ResNet50(weights='imagenet')
    feature_extractor = Model(inputs=resnet_model.inputs, outputs=resnet_model.layers[-2].output)
    
    return caption_model, feature_extractor, tokenizer

# --- C√ÅC H√ÄM X·ª¨ L√ù (L·∫•y t·ª´ notebook) ---

def extract_feature_from_image(feature_extractor, image):
    """Tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng t·ª´ m·ªôt ·∫£nh."""
    image = image.resize((224, 224))
    image = np.array(image)
    
    # Chuy·ªÉn ·∫£nh RGB 3 k√™nh th√†nh 4 chi·ªÅu ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi m√¥ h√¨nh
    if image.shape[2] == 4: # X·ª≠ l√Ω ·∫£nh c√≥ k√™nh alpha (RGBA)
        image = image[..., :3]
        
    image = np.expand_dims(image, axis=0)
    image = preprocess_input(image)
    
    feature = feature_extractor.predict(image, verbose=0)
    return feature

def idx_to_word(integer, tokenizer):
    """Chuy·ªÉn index th√†nh t·ª´."""
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

def predict_caption(model, image_feature, tokenizer, max_length):
    """T·∫°o ch√∫ th√≠ch cho ·∫£nh t·ª´ vector ƒë·∫∑c tr∆∞ng."""
    in_text = 'startseq'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        
        yhat = model.predict([image_feature, sequence], verbose=0)
        
        pred_idx = np.argmax(yhat)
        word = idx_to_word(pred_idx, tokenizer)
        
        if word is None:
            break
        
        in_text += ' ' + word
        
        if word == 'endseq':
            break
            
    return in_text

# --- GIAO DI·ªÜN ·ª®NG D·ª§NG STREAMLIT ---

st.set_page_config(page_title="T·∫°o Ch√∫ Th√≠ch ·∫¢nh Ti·∫øng Vi·ªát", layout="centered")

st.title("Ô∏èüñºÔ∏è T·∫°o Ch√∫ Th√≠ch ·∫¢nh Ti·∫øng Vi·ªát")
st.write("T·∫£i l√™n m·ªôt h√¨nh ·∫£nh v√† m√¥ h√¨nh s·∫Ω t·ª± ƒë·ªông t·∫°o ra m·ªôt ch√∫ th√≠ch b·∫±ng ti·∫øng Vi·ªát m√¥ t·∫£ n·ªôi dung c·ªßa ·∫£nh ƒë√≥.")
st.write("---")

# T·∫£i c√°c m√¥ h√¨nh v√† tokenizer
caption_model, feature_extractor, tokenizer = load_models_and_tokenizer()

# Ki·ªÉm tra n·∫øu t·∫£i m√¥ h√¨nh th√†nh c√¥ng
if caption_model and feature_extractor and tokenizer:
    uploaded_file = st.file_uploader("Ch·ªçn m·ªôt file ·∫£nh...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ t·∫£i l√™n
        image = Image.open(uploaded_file)
        st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_column_width=True)
        
        st.write("")
        
        # T·∫°o ch√∫ th√≠ch khi nh·∫•n n√∫t
        if st.button('T·∫°o ch√∫ th√≠ch'):
            with st.spinner('ƒêang x·ª≠ l√Ω v√† t·∫°o ch√∫ th√≠ch...'):
                max_length = 41 # Gi√° tr·ªã n√†y ƒë∆∞·ª£c x√°c ƒë·ªãnh trong notebook
                
                # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh
                photo_feature = extract_feature_from_image(feature_extractor, image)
                
                # T·∫°o ch√∫ th√≠ch
                generated_caption = predict_caption(caption_model, photo_feature, tokenizer, max_length)
                
                # X·ª≠ l√Ω chu·ªói k·∫øt qu·∫£ cho ƒë·∫πp
                final_caption = generated_caption.replace('startseq', '').replace('endseq', '').strip().capitalize()
                
                st.success('ƒê√£ t·∫°o xong!')
                st.subheader('**Ch√∫ th√≠ch ƒë∆∞·ª£c t·∫°o:**')
                st.write(f"### *{final_caption}*")
else:
    st.warning("·ª®ng d·ª•ng ch∆∞a s·∫µn s√†ng do kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh ho·∫∑c tokenizer. Vui l√≤ng ki·ªÉm tra l·∫°i file.")