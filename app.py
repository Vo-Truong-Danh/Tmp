import streamlit as st
from PIL import Image
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
# D√íNG QUAN TR·ªåNG 1: Import l·ªõp Attention ch√≠nh th·ª©c t·ª´ Keras
from tensorflow.keras.layers import Attention 
import tensorflow as tf


# --- C√ÅC H√ÄM X·ª¨ L√ù ---

@st.cache_resource
def load_all_models():
    # D√íNG QUAN TR·ªåNG 2: Khai b√°o ƒë·ªÉ Keras bi·∫øt "Attention" l√† g√¨ khi t·∫£i model
    custom_objects = {'Attention': Attention}
    
    try:
        # T·∫£i m√¥ h√¨nh v·ªõi custom_objects
        model = load_model('best_model_with_attention.h5', custom_objects=custom_objects)
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i file model 'best_model_with_attention.h5': {e}")
        st.info("H√£y ch·∫Øc ch·∫Øn r·∫±ng b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a ƒë√∫ng l·ªõp Attention ho·∫∑c m√¥ h√¨nh kh√¥ng b·ªã l·ªói.")
        return None, None, None

    try:
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
    except FileNotFoundError:
        st.error("Kh√¥ng t√¨m th·∫•y file 'tokenizer.pkl'. Vui l√≤ng t·∫£i file l√™n.")
        return None, None, None
        
    feature_model = ResNet50(weights='imagenet')
    feature_model = tf.keras.Model(inputs=feature_model.inputs, outputs=feature_model.layers[-2].output)
    
    return model, tokenizer, feature_model

def extract_feature(image, feature_model):
    image = image.resize((224, 224))
    image = np.array(image)
    if image.shape[2] == 4:
        image = image[..., :3]
    image = np.expand_dims(image, axis=0)
    image = preprocess_input(image)
    feature = feature_model.predict(image, verbose=0)
    return feature

def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

def predict_caption(model, image_feature, tokenizer, max_length=34):
    in_text = 'startseq'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        yhat = model.predict([image_feature, sequence], verbose=0)
        pred_id = np.argmax(yhat)
        word = idx_to_word(pred_id, tokenizer)
        if word is None or word == 'endseq':
            break
        in_text += ' ' + word
            
    final_caption = ' '.join(in_text.split()[1:])
    return final_caption.capitalize() + '.'

# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="Chuy·ªÉn ƒë·ªïi H√¨nh ·∫£nh th√†nh VƒÉn b·∫£n", layout="centered")

st.title("Ô∏èChuy·ªÉn ƒë·ªïi H√¨nh ·∫£nh th√†nh VƒÉn b·∫£n üñºÔ∏è‚û°Ô∏èüìù")
st.write("T·∫£i l√™n m·ªôt h√¨nh ·∫£nh v√† m√¥ h√¨nh s·∫Ω t·∫°o ra m·ªôt ch√∫ th√≠ch m√¥ t·∫£ n·ªôi dung c·ªßa ·∫£nh.")

model, tokenizer, feature_model = load_all_models()

uploaded_file = st.file_uploader("Ch·ªçn m·ªôt file ·∫£nh...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None and model is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='·∫¢nh b·∫°n ƒë√£ t·∫£i l√™n', use_column_width=True)
    st.write("")

    if st.button('T·∫°o Ch√∫ Th√≠ch', use_container_width=True):
        with st.spinner('M√¥ h√¨nh ƒëang ph√¢n t√≠ch ·∫£nh, vui l√≤ng ch·ªù...'):
            image_feature = extract_feature(image, feature_model)
            caption = predict_caption(model, image_feature, tokenizer)
            st.subheader("Ch√∫ th√≠ch ƒë∆∞·ª£c t·∫°o ra:")
            st.success(caption)
else:
    if model is None:
        st.warning("Kh√¥ng th·ªÉ t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra l·∫°i file.")
    else:
        st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
