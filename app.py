import streamlit as st
from PIL import Image
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
# --- THAY Äá»”I QUAN TRá»ŒNG ---
# 1. XÃ³a bá» hoÃ n toÃ n pháº§n "class Attention(Layer): ..." mÃ  chÃºng ta tá»± viáº¿t.
# 2. Import trá»±c tiáº¿p lá»›p Attention chÃ­nh thá»©c tá»« thÆ° viá»‡n Keras.
from tensorflow.keras.layers import Attention
import tensorflow as tf


# --- CÃC HÃ€M Xá»¬ LÃ ---

# HÃ m táº£i cÃ¡c model vÃ  tokenizer (Ä‘Æ°á»£c cache láº¡i Ä‘á»ƒ cháº¡y nhanh hÆ¡n)
@st.cache_resource
def load_all_models():
    # Váº«n cáº§n khai bÃ¡o custom_objects Ä‘á»ƒ Keras biáº¿t Ã¡nh xáº¡ tÃªn "Attention" 
    # trong file model tá»›i lá»›p Attention chÃ­nh thá»©c vá»«a import.
    custom_objects = {'Attention': Attention}
    
    # Táº£i mÃ´ hÃ¬nh chÃ­nh
    try:
        model = load_model('best_model_with_attention.h5', custom_objects=custom_objects)
    except Exception as e:
        st.error(f"Lá»—i khi táº£i file model 'best_model_with_attention.h5': {e}")
        st.info("HÃ£y cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ Ä‘á»‹nh nghÄ©a Ä‘Ãºng lá»›p Attention hoáº·c mÃ´ hÃ¬nh khÃ´ng bá»‹ lá»—i.")
        return None, None, None

    # Táº£i tokenizer
    try:
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
    except FileNotFoundError:
        st.error("KhÃ´ng tÃ¬m tháº¥y file 'tokenizer.pkl'. Vui lÃ²ng táº£i file lÃªn.")
        return None, None, None
        
    # Táº£i mÃ´ hÃ¬nh ResNet50 Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh
    feature_model = ResNet50(weights='imagenet')
    # Bá» lá»›p cuá»‘i cÃ¹ng Ä‘á»ƒ láº¥y vector Ä‘áº·c trÆ°ng
    feature_model = tf.keras.Model(inputs=feature_model.inputs, outputs=feature_model.layers[-2].output)
    
    return model, tokenizer, feature_model

def extract_feature(image, feature_model):
    image = image.resize((224, 224))
    image = np.array(image)
    # Náº¿u áº£nh cÃ³ 4 kÃªnh (PNG), bá» kÃªnh alpha
    if image.shape[2] == 4:
        image = image[..., :3]
    image = np.expand_dims(image, axis=0)
    image = preprocess_input(image)
    feature = feature_model.predict(image, verbose=0)
    return feature

def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

def predict_caption(model, image_feature, tokenizer, max_length=34):
    in_text = 'startseq'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        
        # Dá»± Ä‘oÃ¡n
        yhat = model.predict([image_feature, sequence], verbose=0)
        
        # Láº¥y tá»« cÃ³ xÃ¡c suáº¥t cao nháº¥t
        pred_id = np.argmax(yhat)
        word = idx_to_word(pred_id, tokenizer)
        
        if word is None:
            break
        
        in_text += ' ' + word
        
        if word == 'endseq':
            break
            
    # Dá»n dáº¹p cÃ¢u káº¿t quáº£
    final_caption = in_text.split()
    final_caption = final_caption[1:-1] # Bá» 'startseq' vÃ  'endseq'
    final_caption = ' '.join(final_caption)
    return final_caption.capitalize() + '.'

# --- GIAO DIá»†N STREAMLIT ---
st.set_page_config(page_title="Chuyá»ƒn Ä‘á»•i HÃ¬nh áº£nh thÃ nh VÄƒn báº£n", layout="centered")

st.title("ï¸Chuyá»ƒn Ä‘á»•i HÃ¬nh áº£nh thÃ nh VÄƒn báº£n ğŸ–¼ï¸â¡ï¸ğŸ“")
st.write("Táº£i lÃªn má»™t hÃ¬nh áº£nh vÃ  mÃ´ hÃ¬nh sáº½ táº¡o ra má»™t chÃº thÃ­ch mÃ´ táº£ ná»™i dung cá»§a áº£nh.")

# Táº£i model
model, tokenizer, feature_model = load_all_models()

uploaded_file = st.file_uploader("Chá»n má»™t file áº£nh...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None and model is not None:
    # Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ táº£i lÃªn
    image = Image.open(uploaded_file)
    st.image(image, caption='áº¢nh báº¡n Ä‘Ã£ táº£i lÃªn', use_column_width=True)
    st.write("")

    if st.button('Táº¡o ChÃº ThÃ­ch', use_container_width=True):
        with st.spinner('MÃ´ hÃ¬nh Ä‘ang phÃ¢n tÃ­ch áº£nh, vui lÃ²ng chá»...'):
            # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh
            image_feature = extract_feature(image, feature_model)
            
            # Táº¡o chÃº thÃ­ch
            caption = predict_caption(model, image_feature, tokenizer)
            
            st.subheader("ChÃº thÃ­ch Ä‘Æ°á»£c táº¡o ra:")
            st.success(caption)
else:
    if model is None:
        st.warning("KhÃ´ng thá»ƒ táº£i Ä‘Æ°á»£c mÃ´ hÃ¬nh. Vui lÃ²ng kiá»ƒm tra láº¡i file.")
    else:
        st.info("Vui lÃ²ng táº£i áº£nh lÃªn Ä‘á»ƒ báº¯t Ä‘áº§u.")
