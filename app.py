import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
import numpy as np
import pickle
from PIL import Image
import os
import io # ThÃªm import io Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u áº£nh tá»« streamlit

# --- Thiáº¿t láº­p trang ---
st.set_page_config(page_title="TrÃ¬nh táº¡o ChÃº thÃ­ch áº¢nh", layout="centered")

# --- Äá»‹nh nghÄ©a lá»›p Attention tÃ¹y chá»‰nh ---
# Lá»›p nÃ y Cáº¦N PHáº¢I KHá»šP vá»›i lá»›p Attention Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng khi báº¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh.
# Náº¿u khÃ´ng khá»›p, hoáº·c náº¿u mÃ´ hÃ¬nh cá»§a báº¡n khÃ´ng sá»­ dá»¥ng lá»›p Attention, cÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh.
# Lá»—i "Unrecognized keyword arguments passed to LSTM: {'time_major': False}"
# thÆ°á»ng gá»£i Ã½ ráº±ng Keras cáº§n biáº¿t cÃ¡ch táº£i lá»›p tÃ¹y chá»‰nh nÃ y.
class Attention(tf.keras.layers.Layer):
    def __init__(self, units, **kwargs):
        super(Attention, self).__init__(**kwargs)
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V = tf.keras.layers.Dense(1)

    def call(self, features, hidden):
        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)
        # hidden shape == (batch_size, hidden_size)

        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)
        hidden_with_time_axis = tf.expand_dims(hidden, 1)

        # score shape == (batch_size, 64, 1)
        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))

        # attention_weights shape == (batch_size, 64, 1)
        attention_weights = tf.nn.softmax(self.V(score), axis=1)

        # context_vector shape == (batch_size, embedding_dim)
        context_vector = attention_weights * features
        context_vector = tf.reduce_sum(context_vector, axis=1)

        return context_vector, attention_weights

    # get_config lÃ  cáº§n thiáº¿t Ä‘á»ƒ Keras cÃ³ thá»ƒ lÆ°u vÃ  táº£i lá»›p tÃ¹y chá»‰nh
    def get_config(self):
        config = super(Attention, self).get_config()
        # Báº¡n cáº§n thÃªm cÃ¡c Ä‘á»‘i sá»‘ cá»§a hÃ m __init__ vÃ o Ä‘Ã¢y náº¿u cÃ³
        # VÃ­ dá»¥: config.update({'units': self.units})
        # Äá»‘i vá»›i Attention Ä‘Æ¡n giáº£n nÃ y, khÃ´ng cÃ³ Ä‘á»‘i sá»‘ nÃ o cáº§n lÆ°u trong config
        return config


# --- Táº£i Model vÃ  Tokenizer (Sá»­ dá»¥ng cache Ä‘á»ƒ khÃ´ng táº£i láº¡i má»—i láº§n) ---
@st.cache_resource
def load_all_models():
    """
    Táº£i táº¥t cáº£ cÃ¡c model cáº§n thiáº¿t: model táº¡o caption, tokenizer, vÃ  model trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng.
    HÃ m nÃ y Ä‘Æ°á»£c cache Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™.
    """
    with st.spinner('Äang chuáº©n bá»‹ mÃ´ hÃ¬nh, vui lÃ²ng chá» má»™t chÃºt...'):
        try:
            # Táº£i model táº¡o caption Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n
            # Äáº£m báº£o tá»‡p 'best_model_with_attention.h5' náº±m cÃ¹ng thÆ° má»¥c
            # custom_objects cáº§n thiáº¿t Ä‘á»ƒ táº£i lá»›p Attention
            custom_objects = {'Attention': Attention}
            caption_model = load_model('best_model_with_attention.h5', custom_objects=custom_objects)
            st.success("MÃ´ hÃ¬nh táº¡o chÃº thÃ­ch Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")

            # Táº£i tokenizer
            # Äáº£m báº£o tá»‡p 'tokenizer.pkl' náº±m cÃ¹ng thÆ° má»¥c
            with open('tokenizer.pkl', 'rb') as f:
                tokenizer = pickle.load(f)
            st.success("Tokenizer Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")

            # Táº£i model ResNet50 Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng áº£nh
            # ChÃºng ta chá»‰ láº¥y cÃ¡c lá»›p Ä‘áº¿n trÆ°á»›c lá»›p phÃ¢n loáº¡i cuá»‘i cÃ¹ng
            image_model = ResNet50(weights='imagenet')
            # Táº¡o má»™t model má»›i báº±ng cÃ¡ch láº¥y Ä‘áº§u ra cá»§a lá»›p Ã¡p chÃ³t (thÆ°á»ng lÃ  GlobalAveragePooling2D)
            feature_extractor = tf.keras.Model(inputs=image_model.inputs, outputs=image_model.layers[-2].output)
            st.success("MÃ´ hÃ¬nh trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng (ResNet50) Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")

            return caption_model, tokenizer, feature_extractor
        except FileNotFoundError:
            st.error(
                f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y tá»‡p mÃ´ hÃ¬nh hoáº·c tokenizer. "
                f"Vui lÃ²ng Ä‘áº£m báº£o cÃ¡c tá»‡p **best_model_with_attention.h5** vÃ  **tokenizer.pkl** "
                f"náº±m Ä‘Ãºng trong thÆ° má»¥c chá»©a file **app.py**."
            )
            st.stop() # Dá»«ng á»©ng dá»¥ng náº¿u khÃ´ng tÃ¬m tháº¥y tá»‡p
        except Exception as e:
            # Xá»­ lÃ½ lá»—i cá»¥ thá»ƒ náº¿u liÃªn quan Ä‘áº¿n Ä‘á»‘i sá»‘ 'time_major'
            if "Unrecognized keyword arguments passed to LSTM: {'time_major': False}" in str(e):
                st.error(
                    f"Lá»—i khi táº£i model: {e}"
                    f"\n\nÄÃ¢y thÆ°á»ng lÃ  lá»—i khÃ´ng tÆ°Æ¡ng thÃ­ch phiÃªn báº£n TensorFlow/Keras hoáº·c lá»›p Attention. "
                    f"MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i má»™t phiÃªn báº£n Keras/TensorFlow khÃ¡c hoáº·c má»™t Ä‘á»‹nh nghÄ©a lá»›p Attention khÃ¡c. "
                    f"Báº¡n cÃ³ thá»ƒ cáº§n thay Ä‘á»•i phiÃªn báº£n TensorFlow trong requirements.txt "
                    f"(vÃ­ dá»¥: thá»­ `tensorflow==2.11.0` hoáº·c `tensorflow==2.12.0`)."
                    f"\nVui lÃ²ng kiá»ƒm tra láº¡i Ä‘á»‹nh nghÄ©a lá»›p `Attention` trong file nÃ y vÃ  so sÃ¡nh vá»›i mÃ´ hÃ¬nh gá»‘c."
                )
            else:
                st.error(f"Lá»—i khi táº£i model hoáº·c tokenizer: {e}")
            st.stop() # Dá»«ng á»©ng dá»¥ng náº¿u cÃ³ lá»—i táº£i
    return None, None, None # Tráº£ vá» None náº¿u cÃ³ lá»—i

# --- HÃ m trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh ---
def extract_features(image, model):
    """
    Chuyá»ƒn Ä‘á»•i áº£nh ngÆ°á»i dÃ¹ng táº£i lÃªn thÃ nh vector Ä‘áº·c trÆ°ng báº±ng ResNet50.
    """
    # Thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh thÃ nh 224x224 cho phÃ¹ há»£p vá»›i ResNet50
    image = image.resize((224, 224))
    # Chuyá»ƒn áº£nh thÃ nh máº£ng numpy
    image_array = img_to_array(image)
    # ThÃªm má»™t chiá»u Ä‘á»ƒ táº¡o thÃ nh batch size lÃ  1
    image_array = np.expand_dims(image_array, axis=0)
    # Tiá»n xá»­ lÃ½ áº£nh theo cÃ¡ch mÃ  ResNet50 yÃªu cáº§u
    image_array = preprocess_input(image_array)
    # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
    features = model.predict(image_array, verbose=0)
    return features

# --- HÃ m chuyá»ƒn Ä‘á»•i index thÃ nh tá»« ---
def word_for_id(integer, tokenizer):
    """
    TÃ¬m tá»« tÆ°Æ¡ng á»©ng vá»›i má»™t chá»‰ sá»‘ (integer) trong tokenizer.
    """
    # Sá»­ dá»¥ng .get() Ä‘á»ƒ trÃ¡nh lá»—i náº¿u khÃ´ng tÃ¬m tháº¥y index
    return tokenizer.index_word.get(integer)

# --- HÃ m táº¡o Caption (Sá»­ dá»¥ng thuáº­t toÃ¡n Greedy Search) ---
def generate_caption(model, tokenizer, photo_features, max_length):
    """
    Táº¡o ra má»™t cÃ¢u chÃº thÃ­ch tá»« Ä‘áº·c trÆ°ng áº£nh.
    """
    # Báº¯t Ä‘áº§u chuá»—i vá»›i token 'startseq'
    in_text = 'startseq'
    # Láº·p láº¡i Ä‘á»ƒ táº¡o tá»«ng tá»« trong cÃ¢u
    for i in range(max_length): # Sá»­ dá»¥ng i Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p vá»›i max_length
        # Chuyá»ƒn chuá»—i hiá»‡n táº¡i thÃ nh dáº¡ng sá»‘
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        # Padding Ä‘á»ƒ chuá»—i cÃ³ Ä‘á»™ dÃ i cá»‘ Ä‘á»‹nh
        sequence = pad_sequences([sequence], maxlen=max_length)
        
        # Dá»± Ä‘oÃ¡n tá»« tiáº¿p theo
        # Model nháº­n 2 Ä‘áº§u vÃ o: features áº£nh vÃ  chuá»—i vÄƒn báº£n hiá»‡n táº¡i
        yhat = model.predict([photo_features, sequence], verbose=0)
        
        # Láº¥y ra tá»« cÃ³ xÃ¡c suáº¥t cao nháº¥t
        yhat = np.argmax(yhat)
        
        # Chuyá»ƒn tá»« dáº¡ng sá»‘ vá» dáº¡ng chá»¯
        word = word_for_id(yhat, tokenizer)
        
        # Dá»«ng láº¡i náº¿u khÃ´ng tÃ¬m tháº¥y tá»«
        if word is None:
            break
        
        # ThÃªm tá»« vá»«a dá»± Ä‘oÃ¡n vÃ o chuá»—i
        in_text += ' ' + word
        
        # Dá»«ng láº¡i náº¿u gáº·p token 'endseq'
        if word == 'endseq':
            break
            
    # Dá»n dáº¹p cÃ¢u káº¿t quáº£
    final_caption = in_text.split()
    # Loáº¡i bá» 'startseq' vÃ  'endseq'
    if 'startseq' in final_caption:
        final_caption.remove('startseq')
    if 'endseq' in final_caption:
        final_caption.remove('endseq')

    final_caption = ' '.join(final_caption)
    # Viáº¿t hoa chá»¯ cÃ¡i Ä‘áº§u vÃ  thÃªm dáº¥u cháº¥m
    return final_caption.capitalize() + '.'

# --- Giao diá»‡n ngÆ°á»i dÃ¹ng Streamlit ---

st.title("ğŸ“· TrÃ¬nh táº¡o ChÃº thÃ­ch áº¢nh báº±ng AI")
st.write("Táº£i lÃªn má»™t hÃ¬nh áº£nh vÃ  AI sáº½ tá»± Ä‘á»™ng táº¡o ra má»™t cÃ¢u mÃ´ táº£ cho nÃ³.")

# Táº£i cÃ¡c model cáº§n thiáº¿t vÃ  hiá»ƒn thá»‹ thÃ´ng bÃ¡o chá»
caption_model, tokenizer, feature_extractor = load_all_models()

# XÃ¡c Ä‘á»‹nh Ä‘á»™ dÃ i tá»‘i Ä‘a cá»§a caption tá»« cáº¥u trÃºc model
# Input cá»§a model caption thÆ°á»ng lÃ  [features, text_sequence]
# Giáº£ sá»­ input thá»© hai (index 1) lÃ  input cho text sequence, vÃ  chiá»u thá»© hai (index 1) cá»§a nÃ³ lÃ  max_length
try:
    max_caption_length = caption_model.input_shape[1][1]
    st.info(f"Äá»™ dÃ i chÃº thÃ­ch tá»‘i Ä‘a Ä‘Æ°á»£c há»— trá»£: {max_caption_length} tá»«.")
except Exception as e:
    st.warning(f"KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘á»™ dÃ i chÃº thÃ­ch tá»‘i Ä‘a tá»« mÃ´ hÃ¬nh. Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh (34). Lá»—i: {e}")
    max_caption_length = 34 # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c


# Widget Ä‘á»ƒ ngÆ°á»i dÃ¹ng táº£i áº£nh lÃªn
uploaded_file = st.file_uploader("Chá»n má»™t tá»‡p áº£nh...", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    # Má»Ÿ vÃ  hiá»ƒn thá»‹ áº£nh
    image = Image.open(uploaded_file).convert("RGB")

    st.image(image, caption='áº¢nh Ä‘Ã£ táº£i lÃªn', use_column_width=True)
    st.write("") # ThÃªm má»™t khoáº£ng trá»‘ng

    # Khi ngÆ°á»i dÃ¹ng nháº¥n nÃºt
    if st.button('Táº¡o chÃº thÃ­ch! âœ¨'):
        with st.spinner("AI Ä‘ang phÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  suy nghÄ©... ğŸ¤”"):
            # 1. TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh
            features = extract_features(image, feature_extractor)
            
            # 2. Táº¡o chÃº thÃ­ch tá»« Ä‘áº·c trÆ°ng
            caption = generate_caption(caption_model, tokenizer, features, max_caption_length)
            
            # 3. Hiá»ƒn thá»‹ káº¿t quáº£
            st.success("HoÃ n thÃ nh!")
            st.subheader("ChÃº thÃ­ch Ä‘Æ°á»£c táº¡o:")
            st.markdown(f"## *\"{caption}\"*")

st.markdown("---")
st.write("XÃ¢y dá»±ng bá»Ÿi Gemini | Model: ResNet50 + Attention (LSTM/GRU)")

